name: Deploy to Cloud Run

on:
  push:
    branches: [ "main" ]

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  BIGQUERY_DATASET: user_metrics
  BIGQUERY_TABLE: raw_user_level_success
  CONTROL_TABLE_ID: control_level_success
  BUCKET_NAME : caseleveltry
  FOLDER_PATH : case_daily
  
jobs:
  deploy:
    runs-on: ubuntu-latest
    
    permissions:
      contents: 'read'
      id-token: 'write' # For gcp auth

    steps:
    # 1. Cloning repo
    - name: Checkout Repository
      uses: actions/checkout@v4

    # 2. GCP Authentication
    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}

    # 3. Gcloud CLI Installation
    - name: Set up Cloud SDK
      uses: google-github-actions/setup-gcloud@v2
      with:
        project_id: ${{ secrets.GCP_PROJECT_ID }}

    # 5. Deploying on Cloud Run
#    - name: Deploy hello_world_function # Deploy using gcloud functions
#      run: gcloud functions deploy gcs_to_bigquery --region europe-west1 --source cloud_functions --trigger-http --runtime python39  --trigger-resource user-level_try --trigger-event google.storage.object.finalize --entry-point gcs_to_bigquery

    - name: Deploy gcs_to_bigquery function
      run: gcloud functions deploy process_files --region europe-west1 --source cloud_functions --runtime python39 --trigger-http --entry-point process_files --allow-unauthenticated   --set-env-vars PROJECT_ID=$PROJECT_ID,BIGQUERY_DATASET=$BIGQUERY_DATASET,BIGQUERY_TABLE=$BIGQUERY_TABLE,CONTROL_TABLE_ID=$CONTROL_TABLE_ID,BUCKET_NAME=$BUCKET_NAME,FOLDER_PATH=$FOLDER_PATH/



# --trigger-event=providers/cloud.firestore/eventTypes/document.write --trigger-resource=projects/project_id/databases/(default)/documents/messages/{pushId}